# Text Tokenization Using NLTK

This project demonstrates text tokenization using Python's `nltk` library. It performs both word and sentence tokenization, which are common preprocessing steps in Natural Language Processing (NLP).

## Requirements

- Python 3.x
- NLTK (`pip install nltk`)

## Features

- **Word Tokenization**: Splits a block of text into individual words.
- **Sentence Tokenization**: Splits a block of text into individual sentences.

## Usage

1. Install the required NLTK datasets using the following code:

   ```python
   import nltk
   nltk.download('punkt')

2. Ensure your text data is ready for tokenization.

3. Run the script to see the tokenized words and sentences:
   ```bash
   python text_tokenization.py

## License

This project is licensed under the MIT License.
